# Image Segmentation : U-net

![2.png](Image%20Segmentation%20U-net%20f0b574dd914a46e1802c83d6ebbad9e8/2.png)

---

- ì‚¬ì „ ë°°ê²½
    - ì´ë¡ ì  ë°°ê²½ ë° ì—°êµ¬ ëª©ì 
        - Convolution Neural NetworkëŠ” ì´ë¯¸ ì˜¤ë«ë™ì•ˆ ì¡´ì¬í–ˆì§€ë§Œ, ì‚¬ìš© ê°€ëŠ¥í•œ Train Setsì˜ í¬ê¸°ì™€ Networkì˜ í¬ê¸°ë¡œ ì¸í•´ ì„±ê³µì´ ì œí•œë¨
        - ë§ì€ Visual Tasks, íŠ¹íˆ Biomedical Image Processingì—ì„œ ì›í•˜ëŠ” ì¶œë ¥ì—ëŠ” Localizationì´ í¬í•¨ë˜ì–´ì•¼ í–ˆìŒ â‡’ ì¦‰, í´ë˜ìŠ¤ ë ˆì´ë¸”ì´ ê° í”½ì…€ì— í• ë‹¹ë˜ì–´ì•¼ í•œë‹¤ëŠ” ë§ì„
        
        > **CNNë³´ë‹¤ íŠ¹ì§•ì„ ì˜ ì¡ì•„ë‚¼ ìˆ˜ ìˆë„ë¡ ê²½ê³„ ì •ë³´ì™€ íŠ¹ì§•ì„ ì˜ ë³´ì¡´í•˜ì—¬ ì´ë¯¸ì§€ì˜ 
        ë¬¸ë§¥ì„ íŒŒì•…í•´ì•¼ í•˜ëŠ” ë“± ì¡°ê¸ˆ ë” ë†’ì€ ìˆ˜ì¤€ì˜ ì´ë¯¸ì§€ ì´í•´ë¥¼ ìš”êµ¬í•˜ê¸° ìœ„í•¨**
        > 

---

- U-net ì†Œê°œ
    - íŠ¹ì§•
        - ë„“ì€ ë²”ìœ„ì˜ ì´ë¯¸ì§€ í”½ì…€ë¡œë¶€í„° ì˜ë¯¸ì •ë³´ë¥¼ ì¶”ì¶œí•˜ê³  í•´ë‹¹ ì˜ë¯¸ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ 
        ê° í”½ì…€ë§ˆë‹¤ ê°ì²´ë¥¼ ë¶„ë¥˜í•˜ëŠ” Uëª¨ì–‘ì˜ ì•„í‚¤í…ì²˜
        - ê·¼ì ‘í•œ ê°ì²´ ê²½ê³„ë¥¼ ì˜ êµ¬ë¶„í•˜ê²Œ í•™ìŠµí•˜ê¸° ìœ„í•´ Weighted Loss(ê°€ì¤‘ì¹˜ ì˜¤ì°¨) ì œì‹œ
        - Semantic Segmentationì„ ì˜ë£Œìš© Biomedical(ìƒì²´ì˜í•™) Image ë¶„ì„ì— ì‚¬ìš©í•œ ëª¨ë¸
    
    ì´ë¯¸ì§€ë¥¼ **Pixelê¸°ë°˜ìœ¼ë¡œ ë¶„í• **í•˜ëŠ” ì•Œê³ ë¦¬ì¦˜ìœ¼ë¡œ Semantic Segmentationì„ ìˆ˜í–‰
    ë„“ì€ ë²”ìœ„ì˜ ì´ë¯¸ì§€ í”½ì…€ë¡œ ë¶€í„° ì˜ë¯¸ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ê³ , **(ìˆ˜ì¶•ê²½ë¡œ)**
    ì˜ë¯¸ ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê° í”½ì…€ë§ˆë‹¤ ê°ì²´ë¥¼ ë¶„ë¥˜í•˜ëŠ” ê¸°ëŠ¥ **(í™•ì¥ê²½ë¡œ)**
    
    <aside>
    ğŸ’¡ **ì…ë ¥(Input)**ì€ ì´ë¯¸ì§€ì´ë©°, **í”½ì…€ë³„ RGB**ë°ì´í„°ì´ë‹¤.
    **ì¶œë ¥(Output)**ì€ ì´ë¯¸ì§€ì´ë©°, **í”½ì…€ë³„ ê°ì²´ êµ¬ë¶„ ì •ë³´(Class)**ì´ë‹¤.
    
    </aside>
    

---

- **ì‘ë™ ì›ë¦¬** + **Related Work**
    - **Related Work**
        - Semantic Segmentation
            - Segmentation : ì´ë¯¸ì§€ì—ì„œ í”½ì…€ë‹¨ìœ„ë¡œ ê°ì²´ë¥¼ ì¶”ì¶œí•˜ëŠ” ë°©ë²•
            - Semantic Segmentationì€ Image Segmentationì´ë¼ê³ ë„ í•˜ë©°, ì‹¤ì œë¡œ ì¸ì‹í•  ìˆ˜ ìˆëŠ” ë¬¼ë¦¬ì  ì˜ë¯¸ ë‹¨ìœ„ë¡œ ì¸ì‹í•˜ëŠ” Segmentationì„ ì˜ë¯¸í•¨
        - Batch Normalization
            - Normalization
                
                ![optimum](https://user-images.githubusercontent.com/101788136/225791702-18455870-a9ba-482e-b373-ba00e3f4934c.png)
                
                                          (ì¢Œ) Normalization ì ìš©ì „ / (ìš°) Normalization ì ìš©í›„
                
                ---
                
                - ê¸°ë³¸ì ìœ¼ë¡œ ì •ê·œí™”ë¥¼ í•˜ëŠ” ì´ìœ ëŠ” í•™ìŠµì„ ë” ë¹¨ë¦¬ í•˜ê¸° ìœ„í•´ì„œ ë˜ëŠ” Local optimumë¬¸ì œì— ë¹ ì§€ëŠ” ê°€ëŠ¥ì„±ì„ ì¤„ì´ê¸° ìœ„í•´ ì‚¬ìš©ë¨
                - ì •ê·œí™”í•˜ì—¬ ê·¸ë˜í”„ë¥¼ ì™¼ìª½ì—ì„œ ì˜¤ë¥¸ìª½ìœ¼ë¡œ ë§Œë“¤ì–´, Local optimumì— ë¹ ì§ˆ ìˆ˜ ìˆëŠ” ê°€ëŠ¥ì„±ì„ ë‚®ì¶°ì£¼ê²Œ ë¨
                - ì •ê·œí™”ë¥¼ ì‚¬ìš©í•˜ë©´ Gradient Vanishing/Explodingì„ ì–´ëŠì •ë„ ë°©ì§€í•  ìˆ˜ ìˆìŒ.
            - Batch Normalization Background
                - ë‹¨ìˆœíˆ ê³ ì „ì ì¸ ì •ê·œí™” ë°©ì‹ì¸ **Whitening**ë§Œì„ ì‹œí‚¤ë©´ í•´ë‹¹ ê³¼ì •ê³¼ íŒŒë¼ë¯¸í„°ë¥¼ ê³„ì‚°í•˜ê¸° ìœ„í•œ ìµœì í™”ì™€ ë¬´ê´€í•˜ê²Œ ì§„í–‰ë˜ê¸° ë•Œë¬¸ì— íŠ¹ì • íŒŒë¼ë¯¸í„°ê°€ ê³„ì† ì»¤ì§€ëŠ” ìƒíƒœë¡œ Whiteningì´ ì§„í–‰ë  ìˆ˜ ìˆì–´ì„œ Batch Normalizationì´ ë“±ì¥í–ˆìŒ
                - **Whitening**
                    
                    ê° ë ˆì´ì–´ì˜ ì…ë ¥ì˜ ë¶„ì‚°ì„ í‰ê·  0, í‘œì¤€í¸ì°¨ 1ì¸ ì…ë ¥ê°’ìœ¼ë¡œ ì •ê·œí™”ì‹œí‚¤ëŠ” ë°©ë²•
                    
                    Internal Covariance Shift ë•Œë¬¸ì— í•™ìŠµì—ì„œ ë¶ˆì•ˆì •í™”ê°€ ì¼ì–´ë‚˜ Whiteningì„ ì ìš©
                    
                    > Covariate Shift : ì´ì „ ë ˆì´ì–´ì˜ íŒŒë¼ë¯¸í„° ë³€í™”ë¡œ ì¸í•˜ì—¬ í˜„ì¬ ë ˆì´ì–´ì˜ ì…ë ¥ì˜ ë¶„í¬ê°€ ë°”ë€ŒëŠ” í˜„ìƒ
                    Internal Covariate Shift : ë ˆì´ì–´ë¥¼ í†µê³¼í•  ë•Œ ë§ˆë‹¤ Covariate Shiftê°€ ì¼ì–´ë‚˜ë©´ì„œ ì…ë ¥ì˜ ë¶„í¬ê°€ ì•½ê°„ì”© ë³€í•˜ëŠ” í˜„ìƒ
                    > 
            - Batch Normalization : ê° ë ˆì´ì–´ë§ˆë‹¤ ì •ê·œí™”í•˜ëŠ” ë ˆì´ì–´ë¥¼ ë‘ì–´, ë³€í˜•ëœ ë¶„í¬ê°€ ë‚˜ì˜¤ì§€ ì•Šë„ë¡ ì¡°ì ˆí•˜ë©°, í•™ìŠµí•˜ëŠ” ê³¼ì • ìì²´ë¥¼ ì „ì²´ì ìœ¼ë¡œ ì•ˆì •í™”í•˜ì—¬ í•™ìŠµ ì†ë„ë¥¼ ê°€ì† ì‹œí‚¬ ìˆ˜ ìˆëŠ” ê·¼ë³¸ì ì¸ ë°©ë²•ì´ë‹¤.
        - Upsampling / Downsampling
            
            ![2.png](Image%20Segmentation%20U-net%20f0b574dd914a46e1802c83d6ebbad9e8/2%201.png)
            
            - Upsampling : í•´ë‹¹ ë¶„ë¥˜ì— ì†í•˜ëŠ” ë°ì´í„°ê°€ ì ì€ ìª½ì„ í‘œë³¸ìœ¼ë¡œ ë” ì¶”ì¶œí•˜ëŠ” ë°©ë²• 
            â‡’ ì‘ì€ ì‚¬ì§„ì„ í¬ê²Œ í‚¤ìš°ëŠ” ê²ƒ
            - Downsampling : ë°ì´í„°ê°€ ë§ì€ ìª½ì„ ì ê²Œ ì¶”ì¶œí•˜ëŠ” ë°©ë²• 
            â‡’ í° ì‚¬ì§„ì„ ì‘ê²Œ ì¤„ì´ëŠ” ê²ƒ
        - Skip Connection
            - layerì˜ outputì„ ëª‡ ê°œì˜ layerë¥¼ ê±´ë„ˆë›°ê³  ë‹¤ìŒ layerì˜ inputì— ì¶”ê°€í•˜ëŠ” ê¸°ë²•
    - **ì‘ë™ ì›ë¦¬**
        - **Data Preprocessing**
            - Overlap-tile strategy
                
                ì‘ì€ ì˜ì—­ì„ ì˜ˆì¸¡í•˜ê¸° ìœ„í•´ì„œ í° ì˜ì—­ì„ í•™ìŠµí•œë‹¤ê³  ì´í•´í•˜ë©´ ëœë‹¤.
                ê²¹ì¹˜ëŠ” ë¶€ë¶„ì´ ì¡´ì¬í•˜ë„ë¡ ì´ë¯¸ì§€ë¥¼ ìë¥´ê³  Segmentationí•˜ê¸° ë•Œë¬¸ì— Overlap Tileì´ë¼ê³  ë¶ˆë¦°ë‹¤.
                
                ![Untitled](Image%20Segmentation%20U-net%20f0b574dd914a46e1802c83d6ebbad9e8/Untitled.png)
                
                ì´ë¯¸ì§€ì˜ í¬ê¸°ê°€ í° ê²½ìš° ì´ë¯¸ì§€ë¥¼ ìë¥¸ í›„ ê° ì´ë¯¸ì§€ì— í•´ë‹¹í•˜ëŠ” Segmentationì„ ì§„í–‰í•´ì•¼ í•œë‹¤. 
                U-Netì€Â Inputê³¼ Outputì˜ ì´ë¯¸ì§€ í¬ê¸°ê°€ ë‹¤ë¥´ê¸° ë•Œë¬¸ì— ìœ„ ê·¸ë¦¼ì—ì„œ ì²˜ëŸ¼ íŒŒë€ìƒ‰ ì˜ì—­ì„ Inputìœ¼ë¡œ ë„£ìœ¼ë©´ ë…¸ë€ìƒ‰ ì˜ì—­ì´ Outputìœ¼ë¡œ ì¶”ì¶œëœë‹¤. 
                ë™ì¼í•˜ê²Œ ì´ˆë¡ìƒ‰ ì˜ì—­ì„ Segmentationí•˜ê¸° ìœ„í•´ì„œëŠ” **ë¹¨ê°„ìƒ‰ ì˜ì—­ì„ ëª¨ë¸ì˜ Inputìœ¼ë¡œ ì‚¬ìš©**í•´ì•¼ í•œë‹¤. 
                
                ì¦‰,Â **ê²¹ì¹˜ëŠ” ë¶€ë¶„ì´ ì¡´ì¬**í•˜ë„ë¡ ì´ë¯¸ì§€ë¥¼ ìë¥´ê³  Segmentationí•˜ê¸° ë•Œë¬¸ì— Overlap Tile ì „ëµì´ë¼ê³  ë…¼ë¬¸ì—ì„œëŠ” ì§€ì¹­í•œë‹¤.
                
            - Mirroring Extrapolate
                
                ![Untitled](Image%20Segmentation%20U-net%20f0b574dd914a46e1802c83d6ebbad9e8/Untitled%201.png)
                
                ![Untitled](Image%20Segmentation%20U-net%20f0b574dd914a46e1802c83d6ebbad9e8/Untitled%202.png)
                
                ì´ë¯¸ì§€ì˜ ê²½ê³„ë¶€ë¶„ì„ ì˜ˆì¸¡í•  ë•Œì—ëŠ” Paddingì„ ë„£ì–´ í™œìš©í•˜ëŠ” ê²½ìš°ê°€ ì¼ë°˜ì ì´ë‹¤. ë³¸ ë…¼ë¬¸ì—ì„œëŠ” ì´ë¯¸ì§€ ê²½ê³„ì— ìœ„ì¹˜í•œ ì´ë¯¸ì§€ë¥¼ ë³µì‚¬í•˜ê³  ì¢Œìš° ë°˜ì „ì„ 
                í†µí•´Â **Mirror ì´ë¯¸ì§€ë¥¼ ìƒì„±í•œ í›„ ì›ë³¸ ì´ë¯¸ì§€ì˜ ì£¼ë³€ì— ë¶™ì—¬**Â Inputìœ¼ë¡œ ì‚¬ìš©.
                
                > *ë³¸ ë…¼ë¬¸ì˜ ì‹¤í—˜ë¶„ì•¼ì¸ biomedical ì—ì„œëŠ” ì„¸í¬ê°€ ì£¼ë¡œ ë“±ì¥í•˜ê³ , ì„¸í¬ëŠ” ìƒí•˜ ì¢Œìš° ëŒ€ì¹­êµ¬ë„ë¥¼ ì´ë£¨ëŠ” ê²½ìš°ê°€ ë§ê¸° ë•Œë¬¸ì— Mirroring ì „ëµì„ ì‚¬ìš©í–ˆì„ ê²ƒì´ë¼ê³  ì¶”ì¸¡*
                > 
            - Data Augmentation
                
                Dataì˜ ì–‘ì´ ì ìœ¼ë©´ ë°ì´í„° ì¦ê°•ì„ í†µí•´ í’ë¶€í•œ ë°ì´í„°ë¡œ ëª¨ë¸ì´ ë‹¨ë‹¨í•´ì§€ë„ë¡ í•™ìŠµí•œë‹¤. ë…¼ë¬¸ì—ì„œ ì‚¬ìš©í•œ ë°ì´í„° ì¦ê°•ìœ¼ë¡œëŠ” Rotation, Shift, Elastic deformation ë“±ì´ ìˆë‹¤.
                ë…¼ë¬¸ì˜ ì €ìëŠ” ì‘ì€ ë°ì´í„° ì…‹ì„ ê°€ì§€ê³  segmentation networkë¥¼ í•™ìŠµì‹œí‚¬ ë•Œ random elastic deformationì´ key conceptë¡œ ë³´ì¸ë‹¤ê³  í•˜ì˜€ë‹¤.
                
                - Random Elastic Deformation
                    
                    ![Untitled](Image%20Segmentation%20U-net%20f0b574dd914a46e1802c83d6ebbad9e8/Untitled%203.png)
                    
                    Biomedical ë¶„ì•¼ì—ì„œ ë‹¤ì–‘í•œ Deformations ë°©ë²• ì¤‘ Elastic Deformations ì„ ì‚¬ìš©í•œ ì´ìœ ëŠ” ë‹¤ìŒê³¼ ê°™ë‹¤.Â 
                    
                    1) the small amount of available data
                    
                    2) class imbalance
                    
                    ì´ì™€ ê°™ì€ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ elastic transformationì„ ë„ì…í•˜ë‚˜, elastic transformation ì´ì™¸ì—ë„ ë‹¤ë¥¸ augmentationë„ ì¶©ë¶„íˆ ì‚¬ìš© ê°€ëŠ¥í•˜ë‹¤.
                    
                    >Â  Elastic Deformation ì‚¬ìš©ì„ ì¶”ì²œí•˜ëŠ” ê²½ìš° : ì—°ì†ì²´ì—ì„œ ì–´ë–¤ í˜ì´ë‚˜ ì‹œê°„ íë¦„ìœ¼ë¡œ ì¸í•´ ë³€í™”ê°€ ë°œìƒí•˜ëŠ” ê²½ìš°. ì´ í˜ì´ ì œê±°ëœ í›„ ë³€í˜•ì´ ì›ë˜ì²˜ëŸ¼ ëŒì•„ì˜¤ê²Œ ë˜ë©´ ì´ ë³€í˜•ì„ íƒ„ì„±ì´ë¼ê³  í•©ë‹ˆë‹¤. ì´ë ‡ê²Œ íƒ„ì„±ì´ ìˆëŠ” ê²½ìš°ëŠ” ê°™ì€ ë¬¼ì²´ë¼ í•´ë„ ì´¬ì˜ ë°©ë²•ì´ë‚˜ ê°ë„ ë“±ì— ì˜í•´ì„œ ë‹¤ë¥¸ ê²°ê³¼ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì´ëŸ´ ë•Œ ì‚¬ìš©í•˜ë©´ ì¢‹ë‹¤ê³  í•˜ë‚˜ ì´ ì™¸ì˜ ê²½ìš°ì—ë„ ì‚¬ìš© (ì‚¬ëŒì˜ ê¸€ì”¨ì²´ ì°¨ì´ì— ë”°ë¥¸ MNIST ì ìš© ë“±ì—ë„ ì‚¬ìš© í–ˆì—ˆìŒ) ê°€ëŠ¥í•©ë‹ˆë‹¤.
                    
                    ![Untitled](Image%20Segmentation%20U-net%20f0b574dd914a46e1802c83d6ebbad9e8/Untitled%204.png)
                    
        - **Model Structure**
            - ìˆ˜ì¶•ê²½ë¡œ (Contracting Path)
                
                
                ![images_minkyu4506_post_ed171591-5e89-4bc9-bab3-e3be41fb85ef_ìŠ¤í¬ë¦°ìƒ· 2021-08-31 ì˜¤í›„ 4.48.14.png](Image%20Segmentation%20U-net%20f0b574dd914a46e1802c83d6ebbad9e8/images_minkyu4506_post_ed171591-5e89-4bc9-bab3-e3be41fb85ef_%25EC%258A%25A4%25ED%2581%25AC%25EB%25A6%25B0%25EC%2583%25B7_2021-08-31_%25EC%2598%25A4%25ED%259B%2584_4.48.14.png)
                
                ![Untitled](Image%20Segmentation%20U-net%20f0b574dd914a46e1802c83d6ebbad9e8/Untitled%205.png)
                
                <aside>
                â¬‡ï¸ ***Down Sampling***
                **3x3 Conv + ReLu + BatchNormalization (NoPadding, Strides = 1)
                3x3 Conv + ReLu + BatchNormalization (NoPadding, Strides = 1)
                2x2 MaxPooling (Strides = 2)**
                
                </aside>
                
                Downsampling ê³¼ì •ì„ ë°˜ë³µí•˜ì—¬ íŠ¹ì§•ë§µ(Feature Map)ì„ ìƒì„±í•¨
                
                - ì£¼ë³€ í”½ì…€ë“¤ì„ ì°¸ì¡°í•˜ëŠ” ë²”ìœ„(í•„í„°ì˜ ë²”ìœ„)ë¥¼ ë„“í˜€ê°€ë©° ì´ë¯¸ì§€ë¡œë¶€í„° **Contextual ì •ë³´(íŠ¹ì§• ì •ë³´)ë¥¼ ì¶”ì¶œ**í•˜ëŠ” ì—­í• ì„ í•¨
                - ì²˜ìŒ Input Channelì„ ì œì™¸í•˜ê³  Downsampling í•  ë•Œë§ˆë‹¤ Channelì˜ ìˆ˜ë¥¼ 2ë°°ì”© ì¦ê°€ì‹œí‚¤ë©´ì„œ ì§„í–‰í•¨
                    
                    $$
                    1â†’64â†’128â†’256â†’512â†’1024
                    $$
                    
                - **3Ã—3 Convolution**ëŠ” íŒ¨ë”©ì„ í•˜ì§€ ì•Šì•„ íŠ¹ì§•ë§µ(Feature Map)ì˜ í¬ê¸°ê°€ ê°ì†Œí•œë‹¤.
                
                > *ë…¼ë¬¸ì—ì„œëŠ” Batch-Normalizationì´ ì–¸ê¸‰ë˜ì§€ ì•Šì•˜ìœ¼ë‚˜ êµ¬í˜„ì²´ ë° ë‹¤ìˆ˜ì˜ ë¦¬ë·°ì—ì„œ Batch-Normalizationì„ ì‚¬ìš©í•˜ëŠ” ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤.Â [[ì°¸ê³ ìë£Œ]](https://github.com/milesial/Pytorch-UNet)*
                > 
            - ì „í™˜êµ¬ê°„ (Bottle Neck)
                
                <aside>
                â™¾ï¸ ***ì „í™˜***
                **3x3 Conv + ReLu + BatchNormalization (NoPadding, Strides = 1)
                3x3 Conv + ReLu + BatchNormalization (NoPadding, Strides = 1)
                Dropout**
                
                </aside>
                
                ë§ˆì§€ë§‰ì— ì ìš©ëœ **Dropout Layer**ëŠ” ëª¨ë¸ì„Â **ì¼ë°˜í™”í•˜ê³  ë…¸ì´ì¦ˆì— ê²¬ê³ í•˜ê²Œ(Robust)**
                Â **ë§Œë“¤ë©°, ê³¼ì í•©ì„ ë§‰ì•„ì£¼ëŠ” ì¥ì¹˜**ì´ë‹¤.
                
            - í™•ì¥ê²½ë¡œ (Expanding Path)
                
                ![Untitled](Image%20Segmentation%20U-net%20f0b574dd914a46e1802c83d6ebbad9e8/Untitled%206.png)
                
                <aside>
                â¬†ï¸ ***Up Sampling*
                2x2 DeConv (Strides = 2)**
                ìˆ˜ì¶• ê²½ë¡œì—ì„œ ë™ì¼í•œ Levelì˜ íŠ¹ì§•ë§µ(Feature Map)ì„ ì¶”ì¶œí•˜ê³  í¬ê¸°ë¥¼ ë§ì¶”ê¸° ìœ„í•˜ì—¬Â ìë¥¸ í›„(Cropping)Â ì´ì „ Layerì—ì„œ ìƒì„±ëœ íŠ¹ì§•ë§µ(Feature Map)ê³¼Â **ì—°ê²°(Concatenation)**í•©ë‹ˆë‹¤.
                cropì„ í•˜ëŠ” ì´ìœ ëŠ” contracting pathì— ìˆëŠ” feature mapê³¼ expansive pathì— ìˆëŠ” feature mapì˜ í•´ìƒë„ê°€ ê°™ì§€ ì•Šê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.
                **3x3 Conv + ReLu + BatchNormalization (NoPadding, Strides = 1)
                3x3 Conv + ReLu + BatchNormalization (NoPadding, Strides = 1)**
                
                </aside>
                
                í™•ì¥ê²½ë¡œëŠ” ìˆ˜ì¶• ê²½ë¡œì—ì„œ ìƒì„±ëœÂ **Contextual ì •ë³´ì™€ ìœ„ì¹˜ì •ë³´ ê²°í•©**í•˜ëŠ” ì—­í• ì„ í•©ë‹ˆë‹¤.
                **(Kernelì˜ ê°œìˆ˜ë¥¼ ë°˜ìœ¼ë¡œ ì¤„ì¸ CNNì— ì ìš©í•˜ê¸° ì „ì— ë°˜ëŒ€ìª½ contracting pathì—ì„œ ê°™ì€ ì¸µì— ìˆëŠ” feature mapê³¼ í•©ì¹©ë‹ˆë‹¤.)**
                
                - **Upsampling ê³¼ì •** ì„ ë°˜ë³µí•˜ì—¬ íŠ¹ì§•ë§µ(Feature Map)ì„ ìƒì„±
                - ìˆ˜ì¶• ê²½ë¡œì—ì„œ ìƒì„±ëœÂ **Contextual ì •ë³´ì™€ ìœ„ì¹˜ì •ë³´ ê²°í•©**í•˜ëŠ” ì—­í• 
                - ë™ì¼í•œ Levelì—ì„œì˜ ìˆ˜ì¶•ê²½ë¡œì˜ íŠ¹ì§•ë§µê³¼ í™•ì¥ê²½ë¡œì˜ íŠ¹ì§•ë§µì˜ í¬ê¸°ê°€ ë‹¤ë¥¸ ì´ìœ ëŠ” ì—¬ëŸ¬ë²ˆì˜ íŒ¨ë”©ì´ ì—†ëŠ” **3Ã—3 Convolution Layer**ë¥¼ ì§€ë‚˜ë©´ì„œ íŠ¹ì§•ë§µì˜ í¬ê¸°ê°€ ì¤„ì–´ë“¤ê¸° ë•Œë¬¸
                
                CNN -> upsampling -> ë§ì€í¸ contracting pathì˜ feature mapì„ copy and crop -> CNN ->â€¦
                
                ![Untitled](Image%20Segmentation%20U-net%20f0b574dd914a46e1802c83d6ebbad9e8/Untitled%207.png)
                
                <aside>
                â• í™•ì¥ê²½ë¡œì˜ ë§ˆì§€ë§‰ì—ëŠ” Classì˜ ê°¯ìˆ˜ë§Œí¼ í•„í„°ë¥¼ ê°–ê³  ìˆëŠ”Â 
                **1Ã—1 Convolution Layer**ê°€ ìˆìŠµë‹ˆë‹¤.Â 
                **1Ã—1 Convolution Layer**ë¥¼(Classê°œìˆ˜ == ì±„ë„ ê°œìˆ˜) í†µê³¼í•œ í›„Â ê° í”½ì…€ì´ ì–´ë–¤ Classì— í•´ë‹¹í•˜ëŠ”ì§€ì— ëŒ€í•œ ì •ë³´ë¥¼ ë‚˜íƒ€ë‚´ëŠ”Â **3ì°¨ì›(Width Ã— Height Ã— Class) ë²¡í„°**ê°€ ìƒì„±
                
                ![images_minkyu4506_post_f2ecc5e0-0d5e-4677-a2d2-d0d40261e4a7_ìŠ¤í¬ë¦°ìƒ· 2021-08-30 ì˜¤í›„ 9.27.38.png](Image%20Segmentation%20U-net%20f0b574dd914a46e1802c83d6ebbad9e8/images_minkyu4506_post_f2ecc5e0-0d5e-4677-a2d2-d0d40261e4a7_%25EC%258A%25A4%25ED%2581%25AC%25EB%25A6%25B0%25EC%2583%25B7_2021-08-30_%25EC%2598%25A4%25ED%259B%2584_9.27.38.png)
                
                </aside>
                
                - Skip Connectionì„ í†µí•´ ìˆ˜ì¶• ê²½ë¡œì—ì„œ ìƒì„±ëœ Contextual ì •ë³´ì™€ ìœ„ì¹˜ì •ë³´ë¥¼ ê²°í•©í•˜ëŠ” ì—­í• 
        - **Weight Loss**
            
            ![boundary_target.png](Image%20Segmentation%20U-net%20f0b574dd914a46e1802c83d6ebbad9e8/boundary_target.png)
            
            - Biomedical ë¶„ì•¼ë¥¼ ìœ„í•œ ëª¨ë¸ì´ë‹¤ ë³´ë‹ˆ ìœ„ ì´ë¯¸ì§€ì²˜ëŸ¼ ì‘ì€ ê²½ê³„ë¥¼ ë¶„ë¦¬í•  ìˆ˜ ìˆë„ë¡ í•™ìŠµë˜ì–´ì•¼ í•¨
            - ê° í”½ì…€ì´ ê²½ê³„ì™€ ì–¼ë§ˆë‚˜ ê°€ê¹Œìš´ì§€ì— ë”°ë¥¸ Weight-Mapì„ ë§Œë“¤ê³  í•™ìŠµí•  ë•Œ ê²½ê³„ì— ê°€ê¹Œìš´ í”½ì…€ì˜ Lossë¥¼ Weight-Mapì— ë¹„ë¡€í•˜ê²Œ ì¦ê°€ ì‹œí‚´ìœ¼ë¡œì¨ ê²½ê³„ë¥¼ í•™ìŠµí•˜ë„ë¡ í•¨
            - í”½ì…€ê³¼ ê²½ê³„ì˜ ê±°ë¦¬ê°€ ê°€ê¹Œìš°ë©´ í° ê°’ì„ ê°–ê²Œ ë˜ë¯€ë¡œ í•´ë‹¹ í”½ì…€ì˜ Lossê°’ì´ ì»¤ì§€ê²Œ ë¨
            - ìˆ˜ì‹
                
                energy functionì€ ë§¨ ë§ˆì§€ë§‰ì— ì–»ì€ feature mapì— í”½ì…€ ë‹¨ìœ„ë¡œÂ [soft-max](https://en.wikipedia.org/wiki/Softmax_function)ë¥¼ ìˆ˜í–‰í•˜ê³  ì—¬ê¸°ì— cross entropy loss functionì„ ì ìš©í•˜ëŠ” ì‹ì´ë¼ê³  í•˜ëŠ”
                
                ![Untitled](Image%20Segmentation%20U-net%20f0b574dd914a46e1802c83d6ebbad9e8/Untitled%208.png)
                
                ì—¬ê¸°ì„œì˜ xëŠ” íŠ¹ì§•ë§µì— ìˆëŠ” ê° í”½ì…€ì„ ë§í•œë‹¤.
                
                w(x)ëŠ” weight mapì´ë¼ëŠ” í”½ì…€ ë³„ë¡œ ê°€ì¤‘ì¹˜ë¥¼ ë¶€ê³¼í•˜ëŠ” ì—­í• ì´ë‹¤.
                
                ì¦‰, í•œë§ˆë””ë¡œ ì‘ì€ ê²½ê³„ë¥¼ ì˜ ë¶„ë¦¬í•  ìˆ˜ ìˆë„ë¡ í”½ì…€ê³¼ ê²½ê³„ì™€ì˜ ê±°ë¦¬ì— ë”°ë¼ì„œ ê°€ì¤‘ì¹˜ë¥¼ ì¤˜ì„œ ê²½ê³„ë¥¼ í•™ìŠµí•˜ë„ë¡ í•œë‹¤ëŠ” ê²ƒì´ë‹¤.
                
                ![Untitled](Image%20Segmentation%20U-net%20f0b574dd914a46e1802c83d6ebbad9e8/Untitled%209.png)
                
                íŠ¹ì • í´ë˜ìŠ¤ê°€ ê°€ì§€ëŠ” í”½ì…€ì˜ ì£¼íŒŒìˆ˜ì˜ ì°¨ì´ë¥¼ ë³´ì™„í•´ì£¼ëŠ” ì‹ì´ë‹¤.
                
                d1 : ë°”ë¡œ ê°€ì¥ ê°€ê¹Œìš´ í´ë˜ìŠ¤ì˜ í…Œë‘ë¦¬ì™€ì˜ ê±°ë¦¬
                d2 : ë‘ ë²ˆì§¸ë¡œ ê°€ê¹Œìš´ í´ë˜ìŠ¤ì˜ í…Œë‘ë¦¬ì™€ì˜ ê±°ë¦¬
                E = weight map * log(í”½ì…€ì—ì„œ ì–»ì€ í´ë˜ìŠ¤ë³„ ì˜ˆì¸¡ê°’ì„ soft-maxí•œ ê²ƒ)
                

---

- U-net ì½”ë“œ
    
    ì‹¤ì œë¡œ êµ¬í˜„í•´ë³´ê¸° (ëª¨ë¸ ê°€ì ¸ì˜¤ê¸°)
    
    @ë°•ë¯¼ í™•ì¸í•´ì£¼ì„¸ì—¬ :)
    
    [U-net ì‹¤ì œ êµ¬í˜„ ì½”ë“œ](http://machinelearningkorea.com/2019/08/25/u-net-ì‹¤ì œ-êµ¬í˜„-ì½”ë“œ/)
    
    - Conv Block
        
        ![Untitled](Image%20Segmentation%20U-net%20f0b574dd914a46e1802c83d6ebbad9e8/Untitled%2010.png)
        
        ```python
        """ Conv Block """
        class ConvBlock(tf.keras.layers.Layer):
            def __init__(self, n_filters):
                super(ConvBlock, self).__init__()
        
                self.conv1 = Conv2D(n_filters, 3, padding='same')
                self.conv2 = Conv2D(n_filters, 3, padding='same')
        
                self.bn1 = BatchNormalization()
                self.bn2 = BatchNormalization()
        
                self.activation = Activation('relu')
        
            def call(self, inputs):
                x = self.conv1(inputs)
                x = self.bn1(x)
                x = self.activation(x)
        
                x = self.conv2(x)
                x = self.bn2(x)
                x = self.activation(x)
        
                return x
        ```
        
    - Encoder Block
        
        ![Untitled](Image%20Segmentation%20U-net%20f0b574dd914a46e1802c83d6ebbad9e8/Untitled%2011.png)
        
        ```python
        """ Encoder Block """
        class EncoderBlock(tf.keras.layers.Layer):
            def __init__(self, n_filters):
                super(EncoderBlock, self).__init__()
        
                self.conv_blk = ConvBlock(n_filters)
                self.pool = MaxPooling2D((2,2))
        
            def call(self, inputs):
                x = self.conv_blk(inputs)
                p = self.pool(x)
                return x, p
        ```
        
    - Decoder Block
        
        ![Untitled](Image%20Segmentation%20U-net%20f0b574dd914a46e1802c83d6ebbad9e8/Untitled%2012.png)
        
        ```python
        """ Decoder Block """
        class DecoderBlock(tf.keras.layers.Layer):
            def __init__(self, n_filters):
                super(DecoderBlock, self).__init__()
        
                self.up = Conv2DTranspose(n_filters, (2,2), strides=2, padding='same')
                self.conv_blk = ConvBlock(n_filters)
        
            def call(self, inputs, skip):
                x = self.up(inputs)
                x = Concatenate()([x, skip])
                x = self.conv_blk(x)
        
                return x
        ```
        
    - **U-net ì „ì²´ì ì¸ ëª¨ë¸ë§ (*unet_model.py*)**
        
        ```python
        # U-Net model
        # coded by st.watermelon
        
        import tensorflow as tf
        from tensorflow.keras.layers import Conv2D, MaxPooling2D, Conv2DTranspose
        from tensorflow.keras.layers import Activation, BatchNormalization, Concatenate
        
        """ Conv Block """
        class ConvBlock(tf.keras.layers.Layer):
            def __init__(self, n_filters):
                super(ConvBlock, self).__init__()
        
                self.conv1 = Conv2D(n_filters, 3, padding='same')
                self.conv2 = Conv2D(n_filters, 3, padding='same')
        
                self.bn1 = BatchNormalization()
                self.bn2 = BatchNormalization()
        
                self.activation = Activation('relu')
        
            def call(self, inputs):
                x = self.conv1(inputs)
                x = self.bn1(x)
                x = self.activation(x)
        
                x = self.conv2(x)
                x = self.bn2(x)
                x = self.activation(x)
        
                return x
        
        """ Encoder Block """
        class EncoderBlock(tf.keras.layers.Layer):
            def __init__(self, n_filters):
                super(EncoderBlock, self).__init__()
        
                self.conv_blk = ConvBlock(n_filters)
                self.pool = MaxPooling2D((2,2))
        
            def call(self, inputs):
                x = self.conv_blk(inputs)
                p = self.pool(x)
                return x, p
        
        """ Decoder Block """
        class DecoderBlock(tf.keras.layers.Layer):
            def __init__(self, n_filters):
                super(DecoderBlock, self).__init__()
        
                self.up = Conv2DTranspose(n_filters, (2,2), strides=2, padding='same')
                self.conv_blk = ConvBlock(n_filters)
        
            def call(self, inputs, skip):
                x = self.up(inputs)
                x = Concatenate()([x, skip])
                x = self.conv_blk(x)
        
                return x
        
        """ U-Net Model """
        class UNET(tf.keras.Model):
            def __init__(self, n_classes):
                super(UNET, self).__init__()
        
                # Encoder
                self.e1 = EncoderBlock(64)
                self.e2 = EncoderBlock(128)
                self.e3 = EncoderBlock(256)
                self.e4 = EncoderBlock(512)
        
                # Bridge
                self.b = ConvBlock(1024)
        
                # Decoder
                self.d1 = DecoderBlock(512)
                self.d2 = DecoderBlock(256)
                self.d3 = DecoderBlock(128)
                self.d4 = DecoderBlock(64)
        
                # Outputs
                if n_classes == 1:
                    activation = 'sigmoid'
                else:
                    activation = 'softmax'
        
                self.outputs = Conv2D(n_classes, 1, padding='same', activation=activation)
        
            def call(self, inputs):
                s1, p1 = self.e1(inputs)
                s2, p2 = self.e2(p1)
                s3, p3 = self.e3(p2)
                s4, p4 = self.e4(p3)
        
                b = self.b(p4)
        
                d1 = self.d1(b, s4)
                d2 = self.d2(d1, s3)
                d3 = self.d3(d2, s2)
                d4 = self.d4(d3, s1)
        
                outputs = self.outputs(d4)
        
                return outputs
        ```
        

---

- ìš”ì•½
    
    1) Preprocessing
    
    - Overlap-tile strategy
    - Mirroring Extrapolate
    - Data Augumentaion
    
    2) Training
    
    - Contracting Path
    - Bottle Neck
    - Expanding Path
    - Weight Loss
    
    3) Output
    
    ![images_minkyu4506_post_f2ecc5e0-0d5e-4677-a2d2-d0d40261e4a7_ìŠ¤í¬ë¦°ìƒ· 2021-08-30 ì˜¤í›„ 9.27.38.png](Image%20Segmentation%20U-net%20f0b574dd914a46e1802c83d6ebbad9e8/images_minkyu4506_post_f2ecc5e0-0d5e-4677-a2d2-d0d40261e4a7_%25EC%258A%25A4%25ED%2581%25AC%25EB%25A6%25B0%25EC%2583%25B7_2021-08-30_%25EC%2598%25A4%25ED%259B%2584_9.27.38.png)
    
    $$
    Input( w*h*RGB ) \\â†’ Model \\â†’
    Output( w*h*class )
    $$
    
    **ëª¨ë¸ì˜ êµ¬ì¡° ì´í•´í–ˆë‹¤ë©´, Convê³¼ì •ì—ì„œ Paddingì´ ì „í˜€ ì‚¬ìš©ì´ ë˜ì§€ ì•Šìœ¼ë¯€ë¡œ, 
    ëª¨ë¸ì˜ ì¶œë ¥ í¬ê¸°ëŠ” ì…ë ¥í¬ê¸°ë³´ë‹¤ ì‘ì„ ìˆ˜ ë°–ì— ì—†ë‹¤.**
    

---

- ì°¸ê³  ë¬¸í—Œ
    - ë¸”ë¡œê·¸
        
        [[ë…¼ë¬¸ë¦¬ë·°]U-Net - ìƒˆë‚´ê¸° ì½”ë“œ ì—¬í–‰](https://joungheekim.github.io/2020/09/28/paper-review/)
        
        [U-Net ë…¼ë¬¸ ë¦¬ë·°â€Š-â€ŠU-Net: Convolutional Networks for Biomedical Image Segmentation](https://medium.com/@msmapark2/u-net-%EB%85%BC%EB%AC%B8-%EB%A6%AC%EB%B7%B0-u-net-convolutional-networks-for-biomedical-image-segmentation-456d6901b28a)
        
    - ë…¼ë¬¸
        
        [https://arxiv.org/pdf/1505.04597.pdf](https://arxiv.org/pdf/1505.04597.pdf)
        

---
